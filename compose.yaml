services:
  # Kafka Cluster
  zookeeper:
    image: wurstmeister/zookeeper:latest
    ports:
      - "${ZOOKEEPER_PORT}:${ZOOKEEPER_PORT}"
      - "2888:2888" # Follower port
      - "3888:3888" # Election port
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_PORT}
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost ${ZOOKEEPER_PORT} | grep imok"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    volumes:
      - zookeeper_data:/opt/zookeeper-3.4.13/data

  kafka:
    image: wurstmeister/kafka:latest
    restart: "no" 
    ports:
      - "${KAFKA_EXTERNAL_PORT}:${KAFKA_EXTERNAL_PORT}"
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT}
      KAFKA_LISTENERS: INTERNAL://:${KAFKA_INTERNAL_LISTENER_PORT},EXTERNAL://:${KAFKA_EXTERNAL_PORT}
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://${KAFKA_INTERNAL_LISTENER_HOST}:${KAFKA_INTERNAL_LISTENER_PORT},EXTERNAL://${KAFKA_EXTERNAL_HOST}:${KAFKA_EXTERNAL_PORT}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --list --bootstrap-server ${KAFKA_INTERNAL_LISTENER_HOST}:${KAFKA_INTERNAL_LISTENER_PORT} || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 10s
    volumes:
      - kafka_data:/kafka

  kafka-init:
    image: wurstmeister/kafka:latest
    restart: "no"
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      /bin/sh -c "
        echo 'Waiting for Kafka to be ready...'
        until kafka-topics.sh --bootstrap-server ${KAFKA_INTERNAL_LISTENER_HOST}:${KAFKA_INTERNAL_LISTENER_PORT} --list ; do
          sleep 3
        done
        echo 'Kafka is up! Creating topics...'
        
        # Create main topic
        kafka-topics.sh --bootstrap-server ${KAFKA_INTERNAL_LISTENER_HOST}:${KAFKA_INTERNAL_LISTENER_PORT} --create --if-not-exists \
          --topic ${KAFKA_MAIN_TOPIC} \
          --partitions 1 --replication-factor 1
          
        # Create DLQ topic
        kafka-topics.sh --bootstrap-server ${KAFKA_INTERNAL_LISTENER_HOST}:${KAFKA_INTERNAL_LISTENER_PORT} --create --if-not-exists \
          --topic ${KAFKA_DLQ_TOPIC} \
          --partitions 1 --replication-factor 1
          
        echo 'Topics created successfully.'
      "

  kafdrop:
    image: obsidiandynamics/kafdrop
    restart: "on-failure"
    ports:
      - "${KAFDROP_PORT}:9000"
    environment:
      KAFKA_BROKERCONNECT: "${KAFKA_INTERNAL_LISTENER_HOST}:${KAFKA_INTERNAL_LISTENER_PORT}"
    depends_on:
      kafka-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "wget -q -O /dev/null http://localhost:9000 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  redis:
    image: redis:alpine
    restart: always
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s

  # Application Services
  db:
    image: timescale/timescaledb:latest-pg16
    ports:
      - "${DB_PORT}:${DB_PORT}"
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 5
    volumes:
      - postgres_data:/var/lib/postgresql/data

  app:
    image: analytics-api:v1
    build:
      context: .
      dockerfile: Dockerfile.web
    env_file:
      - .env
    ports:
      - "${PORT}:${PORT}"
    command: watchfiles 'uvicorn src.main:app --host 0.0.0.0 --port ${PORT}' src
    volumes:
      - ./src:/app/src:rw
    depends_on:
      db:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    develop:
      watch:
        - action: sync
          path: ./src
          target: /app/src
        - action: rebuild
          path: requirements.txt
        - action: rebuild
          path: Dockerfile.web
  
  # WORKER SERVICE
  worker:
    image: analytics-api:v1 
    restart: always 
    command: ["python", "-m", "src.worker.main"] 
    env_file:
      - .env
    volumes:
      - ./src:/app/src:ro 
    depends_on:
      db:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "find ${WORKER_HEALTHCHECK_FILE_PATH} -mmin -2 | grep . || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 2m 

# Persistent Volumes
volumes:
  postgres_data:
  zookeeper_data:
  kafka_data: